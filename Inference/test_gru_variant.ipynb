{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversarial Neural Cryptography - https://arxiv.org/pdf/1610.06918.pdf\n",
    "# Alternative implementation of the paper above using RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import torch\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the length of the key and the message\n",
    "pln_txt_len = cip_txt_len = 16\n",
    "sec_key_len = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 16]) torch.Size([256, 16])\n"
     ]
    }
   ],
   "source": [
    "# Function to generate a random plain text and a secret key\n",
    "def create_batch(plain_text_len, secret_key_len, batch_size):\n",
    "    plain_text = torch.zeros(batch_size, plain_text_len)\n",
    "    secret_key = torch.zeros(batch_size, secret_key_len)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        for j in range(plain_text_len):\n",
    "            plain_text[i][j] = random.randint(0, 1)\n",
    "        for j in range(secret_key_len):\n",
    "            secret_key[i][j] = random.randint(0, 1)\n",
    "            \n",
    "    return plain_text.float(), secret_key.float()\n",
    "\n",
    "plain_text, secret_key = create_batch(pln_txt_len, sec_key_len, 256)\n",
    "print(plain_text.shape, secret_key.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2070 Super with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "# Define the device\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alice's network\n",
    "# Add plain text and secret key and pass it through a linear layer\n",
    "# Note: plain text and secret key are of the same length\n",
    "\n",
    "class AliceRNN_Net(nn.Module):\n",
    "    def __init__(self, plain_text_len, secret_key_len, cipher_text_len, hidden_size=128):\n",
    "        super(AliceRNN_Net, self).__init__()   \n",
    "        self.input_size  = plain_text_len + secret_key_len  # L + K\n",
    "        self.output_size = cipher_text_len                  # L\n",
    "        self.hidden_size = hidden_size                      # H\n",
    "        \n",
    "        self.C   = nn.Linear(self.input_size, self.output_size)\n",
    "        self.W   = nn.Linear(1, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.U   = nn.Linear(2*hidden_size, 1)\n",
    "        \n",
    "        self.V   = nn.Linear(2*hidden_size, 1)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(2, batch_size, self.hidden_size).to(device)\n",
    "        \n",
    "    def forward(self, plain_text, secret_key, hidden=None):\n",
    "        x = torch.cat((plain_text, secret_key), dim=1)      # B x (L + K)\n",
    "        x = self.C(x).unsqueeze(2)                          # B x L x 1\n",
    "        x = torch.relu(x)                                   # B x L x 1\n",
    "        x = self.W(x)                                       # B x L x H\n",
    "        x = torch.relu(x)                                   # B x L x H\n",
    "        \n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(x.shape[0])           # N x B x H\n",
    "        x, hidden = self.gru(x, hidden)                     # B x L x 2H, 2 x B x H\n",
    "        \n",
    "        x = self.U(x)                                       # B x L x 1\n",
    "        x = torch.sigmoid(x)                                # B x L x 1\n",
    "        x = x.view(-1, self.output_size)                    # B x L\n",
    "        return x\n",
    "    \n",
    "    def encrypt(self, plain_text, secret_key):\n",
    "        encrypted_text = self.forward(plain_text, secret_key)\n",
    "        return torch.as_tensor((encrypted_text - 0.5) > 0, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BobRNN_Net(nn.Module):\n",
    "    def __init__(self, plain_text_len, secret_key_len, cipher_text_len, hidden_size=128):\n",
    "        super(BobRNN_Net, self).__init__()   \n",
    "        self.input_size  = cipher_text_len + secret_key_len     # L + K\n",
    "        self.output_size = plain_text_len                       # L\n",
    "        self.hidden_size = hidden_size                          # H \n",
    "        \n",
    "        self.C   = nn.Linear(self.input_size, self.output_size)\n",
    "        self.W   = nn.Linear(1, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.U   = nn.Linear(2*hidden_size, 1)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(2, batch_size, self.hidden_size).to(device)\n",
    "        \n",
    "    def forward(self, cipher_text, secret_key, hidden=None):\n",
    "        x = torch.cat((cipher_text, secret_key), dim=1)         # B x (L + K)\n",
    "        x = self.C(x).unsqueeze(2)                              # B x L x 1\n",
    "        x = torch.relu(x)                                       # B x L x 1\n",
    "        x = self.W(x)                                           # B x L x H\n",
    "        x = torch.relu(x)                                       # B x L x H\n",
    "        \n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(x.shape[0])               # N x B x H\n",
    "        x, hidden = self.gru(x, hidden)                         # B x L x 2H, 2 x B x H\n",
    "        \n",
    "        x = self.U(x)                                           # B x L x 1\n",
    "        x = torch.sigmoid(x)                                    # B x L x 1\n",
    "        x = x.view(-1, self.output_size)                        # B x L\n",
    "        return x\n",
    "    \n",
    "    def decrypt(self, cipher_text, secret_key):\n",
    "        decrypted_text = self.forward(cipher_text, secret_key)\n",
    "        return torch.as_tensor((decrypted_text - 0.5) > 0, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EveRNN_Net(nn.Module):\n",
    "    def __init__(self, plain_text_len, cipher_text_len, hidden_size=128):\n",
    "        super(EveRNN_Net, self).__init__()  \n",
    "        self.input_size  = cipher_text_len                      # L \n",
    "        self.output_size = plain_text_len                       # L\n",
    "        self.hidden_size = hidden_size                          # H \n",
    "        \n",
    "        self.W   = nn.Linear(1, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.U   = nn.Linear(2 * hidden_size, 1)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(2, batch_size, self.hidden_size).to(device)\n",
    "        \n",
    "    def forward(self, cipher_text, hidden=None):\n",
    "        x = cipher_text.unsqueeze(2)                            # B x L x 1\n",
    "        x = self.W(x)                                           # B x L x H\n",
    "        x = torch.relu(x)                                       # B x L x H\n",
    "        \n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(x.shape[0])               # N x B x H\n",
    "        x, hidden = self.gru(x, hidden)                         # B x L x 2H, 2 x B x H\n",
    "        \n",
    "        x = self.U(x)                                           # B x L x 1\n",
    "        x = torch.sigmoid(x)                                    # B x L x 1\n",
    "        x = x.view(-1, self.output_size)                        # B x L\n",
    "        return x\n",
    "    \n",
    "    def eavesdrop(self, cipher_text):\n",
    "        eavesdrop_text = self.forward(cipher_text)\n",
    "        return torch.as_tensor((eavesdrop_text - 0.5) > 0, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models instantiated successfully !!!\n"
     ]
    }
   ],
   "source": [
    "# Declare the hidden size\n",
    "hidden_size = 128\n",
    "\n",
    "# Instantiate the models\n",
    "Alice = AliceRNN_Net(pln_txt_len, sec_key_len, cip_txt_len, hidden_size).to(device)\n",
    "Bob   = BobRNN_Net(pln_txt_len, sec_key_len, cip_txt_len, hidden_size).to(device)\n",
    "Eve   = EveRNN_Net(pln_txt_len, cip_txt_len, hidden_size).to(device)\n",
    "\n",
    "print(\"All models instantiated successfully !!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded successfully !!!\n"
     ]
    }
   ],
   "source": [
    "# Import saved the models\n",
    "Alice.load_state_dict(torch.load(\"../GRU_models/GRU_Alice.pth\"))\n",
    "Bob.load_state_dict(torch.load(\"../GRU_models/GRU_Bob.pth\"))\n",
    "Eve.load_state_dict(torch.load(\"../GRU_models/GRU_Eve.pth\"))\n",
    "\n",
    "print(\"Models loaded successfully !!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance(x, y):\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        if x[i] != y[i]:\n",
    "            count += 1\n",
    "    \n",
    "    return count   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain text:   1010101100110110\n",
      "Cipher text:  1010000100110001\n",
      "Bob's output: 1110100100110110 Distance: 2\n",
      "Eve's output: 0010100000111100 Distance: 5\n"
     ]
    }
   ],
   "source": [
    "# Set the models to evaluation mode\n",
    "Alice.eval()\n",
    "Bob.eval()\n",
    "Eve.eval()\n",
    "\n",
    "# Test the networks\n",
    "plain_text, secret_key = create_batch(pln_txt_len, sec_key_len, 1)\n",
    "plain_text, secret_key = plain_text.to(device), secret_key.to(device)\n",
    "\n",
    "# Encrypt and decrypt the plain text\n",
    "encrypted_text = Alice.encrypt(plain_text, secret_key)\n",
    "decrypted_text = Bob.decrypt(encrypted_text, secret_key)\n",
    "eavesdrop_text = Eve.eavesdrop(encrypted_text)\n",
    "\n",
    "plain_text     = plain_text.detach().cpu().squeeze().numpy()\n",
    "plain_text     = \"\".join(str(int(i)) for i in plain_text)\n",
    "\n",
    "encrypted_text = encrypted_text.detach().cpu().squeeze().numpy()\n",
    "encrypted_text = \"\".join(str(int(i)) for i in encrypted_text)\n",
    "\n",
    "decrypted_text = decrypted_text.detach().cpu().squeeze().numpy()\n",
    "decrypted_text = \"\".join(str(int(i)) for i in decrypted_text)\n",
    "\n",
    "eavesdrop_text = eavesdrop_text.detach().cpu().squeeze().numpy()\n",
    "eavesdrop_text = \"\".join(str(int(i)) for i in eavesdrop_text)\n",
    "\n",
    "print(\"Plain text:  \", plain_text)\n",
    "print(\"Cipher text: \", encrypted_text)\n",
    "\n",
    "print(\"Bob's output:\", decrypted_text, \"Distance:\", hamming_distance(plain_text, decrypted_text))\n",
    "print(\"Eve's output:\", eavesdrop_text, \"Distance:\", hamming_distance(plain_text, eavesdrop_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
