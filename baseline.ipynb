{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversarial Neural Cryptography - https://arxiv.org/pdf/1610.06918.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radheshyam/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Necessary imports\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the length of the key and the message\n",
    "pln_txt_len = sec_key_len = cip_txt_len = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 8]) torch.Size([256, 8])\n"
     ]
    }
   ],
   "source": [
    "# Function to generate a random plain text and a secret key\n",
    "def create_batch(plain_text_len, secret_key_len, batch_size):\n",
    "    plain_text = torch.zeros(batch_size, plain_text_len)\n",
    "    secret_key = torch.zeros(batch_size, secret_key_len)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        for j in range(plain_text_len):\n",
    "            plain_text[i][j] = random.randint(0, 1) * 2 - 1\n",
    "        for j in range(secret_key_len):\n",
    "            secret_key[i][j] = random.randint(0, 1) * 2 - 1\n",
    "            \n",
    "    return plain_text, secret_key\n",
    "\n",
    "plain_text, secret_key = create_batch(pln_txt_len, sec_key_len, 256)\n",
    "print(plain_text.shape, secret_key.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alice's network\n",
    "\n",
    "class Alice_Net(nn.Module):\n",
    "    def __init__(self, plain_text_len, secret_key_len, cipher_text_len):\n",
    "        super(Alice_Net, self).__init__()\n",
    "        self.input_size  = plain_text_len + secret_key_len\n",
    "        self.output_size = cipher_text_len\n",
    "        \n",
    "        self.W = nn.Linear(self.input_size, self.input_size)\n",
    "        self.C = nn.Sequential(\n",
    "            nn.Conv1d(1, 2, 4, stride=1, padding=2),\n",
    "            nn.Sigmoid(),  \n",
    "            nn.Conv1d(2, 4, 2, stride=2, padding=0),\n",
    "            nn.Sigmoid(), \n",
    "            nn.Conv1d(4, 4, 1, stride=1, padding=0),\n",
    "            nn.Sigmoid(),   \n",
    "            nn.Conv1d(4, 1, 1, stride=1, padding=0),\n",
    "            nn.Tanh(),      \n",
    "            )\n",
    "        \n",
    "    def forward(self, plain_text, secret_key):\n",
    "        x = torch.cat((plain_text, secret_key), 1)\n",
    "        x = torch.reshape(x, (x.shape[0], 1, x.shape[1]))\n",
    "        x = self.W(x)\n",
    "        x = self.C(x)\n",
    "        x = torch.squeeze(x)\n",
    "        return x\n",
    "    \n",
    "    def encrypt(self, plain_text, secret_key):\n",
    "        return self.forward(plain_text, secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bob's network\n",
    "\n",
    "class Bob_Net(nn.Module):\n",
    "    def __init__(self, plain_text_len, secret_key_len, cipher_text_len):\n",
    "        super(Bob_Net, self).__init__()\n",
    "        self.input_size  = cipher_text_len + secret_key_len\n",
    "        self.output_size = plain_text_len\n",
    "        \n",
    "        self.W = nn.Linear(self.input_size, self.input_size)\n",
    "        self.C = nn.Sequential(\n",
    "            nn.Conv1d(1, 2, 4, stride=1, padding=2),\n",
    "            nn.Sigmoid(),  \n",
    "            nn.Conv1d(2, 4, 2, stride=2, padding=0),\n",
    "            nn.Sigmoid(), \n",
    "            nn.Conv1d(4, 4, 1, stride=1, padding=0),\n",
    "            nn.Sigmoid(),   \n",
    "            nn.Conv1d(4, 1, 1, stride=1, padding=0),\n",
    "            nn.Tanh(),      \n",
    "            )\n",
    "        \n",
    "    def forward(self, cipher_text, secret_key):\n",
    "        x = torch.cat((cipher_text, secret_key), 1)\n",
    "        x = torch.reshape(x, (x.shape[0], 1, x.shape[1]))\n",
    "        x = self.W(x)\n",
    "        x = self.C(x)\n",
    "        x = torch.squeeze(x)\n",
    "        return x\n",
    "    \n",
    "    def decrypt(self, cipher_text, secret_key):\n",
    "        return self.forward(cipher_text, secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eve's network\n",
    "\n",
    "class Eve_Net(nn.Module):\n",
    "    def __init__(self, plain_text_len, cipher_text_len):\n",
    "        super(Eve_Net, self).__init__()\n",
    "        self.input_size  = cipher_text_len\n",
    "        self.output_size = plain_text_len\n",
    "        \n",
    "        self.W = nn.Linear(self.input_size, 2 * self.input_size)\n",
    "        self.C = nn.Sequential(\n",
    "            nn.Conv1d(1, 2, 4, stride=1, padding=2),\n",
    "            nn.Sigmoid(),  \n",
    "            nn.Conv1d(2, 4, 2, stride=2, padding=0),\n",
    "            nn.Sigmoid(), \n",
    "            nn.Conv1d(4, 4, 1, stride=1, padding=0),\n",
    "            nn.Sigmoid(),   \n",
    "            nn.Conv1d(4, 1, 1, stride=1, padding=0),\n",
    "            nn.Tanh(),      \n",
    "            )\n",
    "        \n",
    "    def forward(self, cipher_text):\n",
    "        x = torch.reshape(cipher_text, (cipher_text.shape[0], 1, cipher_text.shape[1]))\n",
    "        x = self.W(x)\n",
    "        x = self.C(x)\n",
    "        x = torch.squeeze(x)\n",
    "        return x\n",
    "    \n",
    "    def eavesdrop(self, cipher_text):\n",
    "        return self.forward(cipher_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets define the Loss Functions\n",
    "Alice and Bob want to minimize Bob’s reconstruction error and to\n",
    "maximize the reconstruction error of the “optimal Eve”.\n",
    "\n",
    "Eve's Loss function is the L1 distance between Eve’s guess and the input plaintext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EveLoss(Plain, Decrypt, BatchSize):\n",
    "    return torch.sum(torch.abs((Plain - Decrypt)/2)) / BatchSize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alice and Bob Loss has two components:\n",
    "1. The reconstruction error of Bob. which is just like eve L1 error between decrypted and plaintext\n",
    "2. How good previous eve is in breaking the current moedl. For this we use: (N/2 − Eve_L1_error)^2 /(N/2)^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AliceBobLoss(Plain, Decrypt, BatchSize, prevEveLoss):\n",
    "    loss1 = torch.sum(torch.abs((Plain - Decrypt)/2)) / BatchSize\n",
    "    loss2 = ((pln_txt_len/2 - prevEveLoss)**2)/(pln_txt_len/2)**2\n",
    "    return loss1 + loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the networks\n",
    "\n",
    "# We use TensorFlow’s Adam (Kingma & Ba, 2014) optimizer with a learning rate of 0.0008\n",
    "# Alice/Bob training for one minibatch, and then\n",
    "# Eve training for two minibatches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
